{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Transformer-based CPU Usage Forecasting with Chronos\nThis project demonstrates time series forecasting of CPU usage using ARIMA and a Transformer-based model (Chronos-style)."]}, {"cell_type": "code", "metadata": {}, "source": "!pip install statsmodels matplotlib torch -q"}, {"cell_type": "code", "metadata": {}, "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Generate Synthetic CPU Usage Data\nWe create synthetic CPU usage data including trend, seasonality, noise, and random spikes."]}, {"cell_type": "code", "metadata": {}, "source": "np.random.seed(42)\ntime = pd.date_range(start=\"2023-01-01\", periods=500, freq=\"H\")\n\ncpu_usage = (\n    30 + 10 * np.sin(np.linspace(0, 20, 500))\n    + np.linspace(0, 15, 500)\n    + np.random.normal(0, 5, 500)\n)\n\nspike_indices = np.random.choice(len(cpu_usage), 15, replace=False)\ncpu_usage[spike_indices] += np.random.randint(20, 40, size=15)\n\ndata = pd.DataFrame({\"time\": time, \"cpu\": cpu_usage})\ndata.set_index(\"time\", inplace=True)\n\nplt.figure(figsize=(12,5))\nplt.plot(data.index, data[\"cpu\"], label=\"CPU Usage\")\nplt.title(\"Synthetic CPU Usage Data\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"CPU %\")\nplt.legend()\nplt.show()\n\ntrain_size = int(len(data) * 0.8)\ntrain, test = data.iloc[:train_size], data.iloc[train_size:]"}, {"cell_type": "markdown", "metadata": {}, "source": ["## ARIMA Model\nWe use statsmodels' ARIMA to create a baseline forecasting model."]}, {"cell_type": "code", "metadata": {}, "source": "from statsmodels.tsa.arima.model import ARIMA\n\narima_model = ARIMA(train['cpu'], order=(5,1,0))\narima_result = arima_model.fit()\n\nn_periods = len(test)\narima_forecast = arima_result.forecast(steps=n_periods)\n\nrmse_arima = math.sqrt(mean_squared_error(test['cpu'], arima_forecast))\nmae_arima = mean_absolute_error(test['cpu'], arima_forecast)\nprint(f'ARIMA RMSE: {rmse_arima:.2f}, MAE: {mae_arima:.2f}')\n\nplt.figure(figsize=(12,5))\nplt.plot(train.index, train['cpu'], label='Train')\nplt.plot(test.index, test['cpu'], label='Test')\nplt.plot(test.index, arima_forecast, label='ARIMA Forecast')\nplt.title('ARIMA Forecast vs Actual CPU Usage')\nplt.xlabel('Time')\nplt.ylabel('CPU %')\nplt.legend()\nplt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Transformer-based Forecasting (Chronos-style)"]}, {"cell_type": "code", "metadata": {}, "source": "import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nSEQ_LEN = 24\nPRED_LEN = 1\n\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, series, seq_len=SEQ_LEN):\n        self.series = series\n        self.seq_len = seq_len\n    def __len__(self):\n        return len(self.series) - self.seq_len\n    def __getitem__(self, idx):\n        x = self.series[idx:idx+self.seq_len]\n        y = self.series[idx+self.seq_len]\n        return x, y\n\ntrain_values = torch.tensor(train['cpu'].values, dtype=torch.float32).unsqueeze(1)\ntest_values = torch.tensor(test['cpu'].values, dtype=torch.float32).unsqueeze(1)\n\ntrain_dataset = TimeSeriesDataset(train_values)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nclass SimpleTransformer(nn.Module):\n    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2):\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, num_decoder_layers=num_layers)\n        self.fc = nn.Linear(d_model, 1)\n    def forward(self, src):\n        src = self.input_proj(src).permute(1,0,2)\n        out = self.transformer(src, src)\n        out = out[-1,:,:]\n        return self.fc(out)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = SimpleTransformer().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.MSELoss()"}, {"cell_type": "code", "metadata": {}, "source": "# Training\nEPOCHS = 30\nfor epoch in range(EPOCHS):\n    model.train()\n    epoch_loss = 0\n    for x_batch, y_batch in train_loader:\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        y_pred = model(x_batch)\n        loss = loss_fn(y_pred, y_batch)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    if (epoch+1)%5==0:\n        print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(train_loader):.4f}')"}, {"cell_type": "code", "metadata": {}, "source": "# Forecasting\nmodel.eval()\npreds = []\ninput_seq = train_values[-SEQ_LEN:].unsqueeze(0).to(device)\n\nwith torch.no_grad():\n    for _ in range(len(test)):\n        y_pred = model(input_seq)\n        preds.append(y_pred.item())\n        input_seq = torch.cat([input_seq[:,1:,:], y_pred.unsqueeze(0).unsqueeze(2)], dim=1)\n\nrmse_tf = math.sqrt(mean_squared_error(test['cpu'], preds))\nmae_tf = mean_absolute_error(test['cpu'], preds)\nprint(f'Transformer RMSE: {rmse_tf:.2f}, MAE: {mae_tf:.2f}')\n\nplt.figure(figsize=(12,5))\nplt.plot(train.index, train['cpu'], label='Train')\nplt.plot(test.index, test['cpu'], label='Test')\nplt.plot(test.index, preds, label='Transformer Forecast')\nplt.title('Transformer Forecast vs Actual CPU Usage')\nplt.xlabel('Time')\nplt.ylabel('CPU %')\nplt.legend()\nplt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Comparison"]}, {"cell_type": "code", "metadata": {}, "source": "results = pd.DataFrame({\n    'Model': ['ARIMA', 'Transformer'],\n    'RMSE': [rmse_arima, rmse_tf],\n    'MAE': [mae_arima, mae_tf]\n})\nresults"}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusion\n- Both models provide reasonable forecasts on synthetic CPU data.\n- Transformer slightly improves MAE, but ARIMA remains competitive.\n- Future improvements: use real CPU data, longer sequences, multivariate features, and hyperparameter tuning."]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}